{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"red\">**Assignment 8 Analisi e Classificazione delle Email per la Rilevazione di SPAM**</font>\n",
        "ProfessionAI, azienda specializzata nell'automazione basata sull'Intelligenza Artificiale, vuole sviluppare una libreria software in grado di analizzare e classificare le email ricevute. L'obiettivo principale è identificare le email di tipo SPAM per condurre successivamente delle analisi approfondite sui contenuti.\n",
        "\n",
        "Il CEO ha espresso l'esigenza di focalizzarsi su email SPAM per comprendere meglio le tendenze, i contenuti e i comportamenti associati. Queste informazioni verranno utilizzate per migliorare la sicurezza delle comunicazioni aziendali e perfezionare i filtri anti-spam.\n",
        "\n",
        "# <font color=\"red\">**Obiettivo del Progetto**</font>\n",
        "Il CTO ha fornito un dataset di email per realizzare le seguenti attività:\n",
        " 1. **Addestrare un classificatore** per identificare le email SPAM.\n",
        " 2. **Individuare i Topic principali** tra le email classificate come SPAM.\n",
        " 3. **Calcolare la distanza semantica** tra i topics ottenuti per valutare l'eterogeneità dei contenuti delle email SPAM.\n",
        " 4. **Estrarre dalle email NON SPAM** le informazioni sulle Organizzazioni menzionate.\n",
        "\n",
        "\n",
        "# <font color=\"red\">**Valore Aggiunto**</font>\n",
        "L'analisi delle email permette a ProfessionAI di ottenere diversi vantaggi strategici:\n",
        "- **Miglioramento del filtro anti-spam**: Un classificatore efficiente permette di ridurre significativamente il volume di email indesiderate che raggiungono la casella di posta, ottimizzando la gestione delle comunicazioni aziendali.\n",
        "- **Analisi contenutistica approfondita**: L'individuazione dei principali topic trattati nelle email SPAM consente di ottenere informazioni preziose sui trend, tematiche e schemi ricorrenti, potenziando le strategie di cybersecurity.\n",
        "- **Valutazione dell'eterogeneità**: La distanza semantica tra i topic consente di comprendere la diversità dei contenuti SPAM, utile per ottimizzare le difese contro un'ampia gamma di attacchi.\n",
        "- **Identificazione di organizzazioni**: L'estrazione di organizzazioni dalle email legittime può essere sfruttata per migliorare i processi di business intelligence e gestire meglio le comunicazioni con clienti e partner."
      ],
      "metadata": {
        "id": "EfDB4Z2KeV9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installazione pacchetti**"
      ],
      "metadata": {
        "id": "s_gCZ2MIh9fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1BfCcHxh5q0",
        "outputId": "e15af0db-7e00-44a8-8c87-aab6cce417e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import delle librerie necessarie\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from gensim import corpora, models\n",
        "import string"
      ],
      "metadata": {
        "id": "F5wt-kMfBYb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"yellow\">***Caricamento Dataset & Data Cleaning***</font>"
      ],
      "metadata": {
        "id": "0_uU_S1AhJxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# caricamento dataset\n",
        "url = (\"https://raw.githubusercontent.com/ProfAI/natural-language-processing/\"\n",
        "       \"main/datasets/Verifica%20Finale%20-%20Spam%20Detection/spam_dataset.csv\")\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "1TlolgNRkPnh",
        "outputId": "cc745a2b-26ac-480d-f966-ef858ed3db7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      Unnamed: 0 label                                               text  \\\n",
              "0            605   ham  Subject: enron methanol ; meter # : 988291\\nth...   \n",
              "1           2349   ham  Subject: hpl nom for january 9 , 2001\\n( see a...   \n",
              "2           3624   ham  Subject: neon retreat\\nho ho ho , we ' re arou...   \n",
              "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
              "4           2030   ham  Subject: re : indian springs\\nthis deal is to ...   \n",
              "...          ...   ...                                                ...   \n",
              "5166        1518   ham  Subject: put the 10 on the ft\\nthe transport v...   \n",
              "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\nhpl ...   \n",
              "5168        2933   ham  Subject: calpine daily gas nomination\\n>\\n>\\nj...   \n",
              "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
              "5170        4807  spam  Subject: important online banking alert\\ndear ...   \n",
              "\n",
              "      label_num  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             1  \n",
              "4             0  \n",
              "...         ...  \n",
              "5166          0  \n",
              "5167          0  \n",
              "5168          0  \n",
              "5169          0  \n",
              "5170          1  \n",
              "\n",
              "[5171 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a24ac3fa-f9a7-4806-8602-0be2affe4b5c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>605</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: enron methanol ; meter # : 988291\\nth...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2349</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: hpl nom for january 9 , 2001\\n( see a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3624</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: neon retreat\\nho ho ho , we ' re arou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4685</td>\n",
              "      <td>spam</td>\n",
              "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2030</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: re : indian springs\\nthis deal is to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5166</th>\n",
              "      <td>1518</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: put the 10 on the ft\\nthe transport v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5167</th>\n",
              "      <td>404</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: 3 / 4 / 2000 and following noms\\nhpl ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5168</th>\n",
              "      <td>2933</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: calpine daily gas nomination\\n&gt;\\n&gt;\\nj...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5169</th>\n",
              "      <td>1409</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: industrial worksheets for august 2000...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5170</th>\n",
              "      <td>4807</td>\n",
              "      <td>spam</td>\n",
              "      <td>Subject: important online banking alert\\ndear ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5171 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a24ac3fa-f9a7-4806-8602-0be2affe4b5c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a24ac3fa-f9a7-4806-8602-0be2affe4b5c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a24ac3fa-f9a7-4806-8602-0be2affe4b5c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e46d30dd-5819-4fd7-ab46-f2d7c9964594\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e46d30dd-5819-4fd7-ab46-f2d7c9964594')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e46d30dd-5819-4fd7-ab46-f2d7c9964594 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_bca5c68d-5251-4a11-a3ad-df7a1271e8d9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bca5c68d-5251-4a11-a3ad-df7a1271e8d9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5171,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1492,\n        \"min\": 0,\n        \"max\": 5170,\n        \"num_unique_values\": 5171,\n        \"samples\": [\n          2924,\n          3839,\n          3078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4993,\n        \"samples\": [\n          \"Subject: hpl / conoco - teco waha 03 / 23 / 01 purchase\\ndaren , conoco invoiced hpl at $ 5 . 87 for 03 / 23 at pgev / waha and deal ticket 685350 shows $ 4 . 87 . can you confirm the price ? thanks .\",\n          \"Subject: holiday on - call data\\npipeline contact phone fax pager\\nblack marlin blair lichentwalter 713 853 - 7367 713 646 - 3201 ( h )\\n281 370 - 1866\\ndebbie thompson 713 853 - 3144 713 646 - 3201\\n( noms due today for 23 rd through 27 th )\\nchannel jim tobacco 713 420 - 2159\\ngas control 1 505 599 - 2333\\n( open thursday . noms will be due through monday )\\ncentana william spekels 713 627 - 6290 713 762 - 3450\\ndonna spencer 713 627 - 6255\\ngas control 1 888 204 - 1718\\n( noms due today for 23 rd through 27 th )\\nduke energy annette anderson 713 260 - 8603 713 949 - 3026\\n( on call ) bob moseman 713 - 260 - 8698 ( thursday )\\nopen tomorrow - noms will be due thru the 27 th )\\nlonestar gary gafford 214 670 - 2674 214 875 - 3810\\ngas control 214 875 - 2455 or 2456\\n( noms due today , 23 rd thru 27 th )\\nnorthern natural ben markey 853 - 7581 cell 713 446 - 9404 800 931 - 0398\\n( on call ) charlie mosey 853 - 1520\\ngas control 853 -\\n( open thursday - noms due thru 27 th . )\\neast trans - east texas\\ntejas gas control 713 767 - 5366\\npaula svehla 713 230 - 3569\\nmickey chapman 713 230 - 3546\\n( open thursday - noms due thru 27 th )\\nmidcon ( y 2 k ) ken nachlinger 713 369 - 9284 713 369 - 9375 888 733 - 5954\\n( on call ) steven 888 790 - 0255\\n( y 2 k ) don 888 733 - 4602\\ngas control 713 369 - 9200\\n( noms due today , 23 rd thru 27 th )\\nmoss bluff no current business\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vedo alcuni esempi di testo e la relativa classificazione\n",
        "print(df['text'].iloc[0],'\\n\\n',df['label'].iloc[0],  '\\n\\n')\n",
        "print(df['text'].iloc[10],'\\n\\n',df['label'].iloc[10], '\\n\\n')\n",
        "print(df['text'].iloc[100],'\\n\\n',df['label'].iloc[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAxhYBnglZQ0",
        "outputId": "22a9a551-6d56-422b-a58e-a62c37a5f3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject: enron methanol ; meter # : 988291\n",
            "this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\n",
            "flow data provided by daren } .\n",
            "please override pop ' s daily volume { presently zero } to reflect daily\n",
            "activity you can obtain from gas control .\n",
            "this change is needed asap for economics purposes . \n",
            "\n",
            " ham \n",
            "\n",
            "\n",
            "Subject: vocable % rnd - word asceticism\n",
            "vcsc - brand new stock for your attention\n",
            "vocalscape inc - the stock symbol is : vcsc\n",
            "vcsc will be our top stock pick for the month of april - stock expected to\n",
            "bounce to 12 cents level\n",
            "the stock hit its all time low and will bounce back\n",
            "stock is going to explode in next 5 days - watch it soar\n",
            "watch the stock go crazy this and next week .\n",
            "breaking news - vocalscape inc . announces agreement to resell mix network\n",
            "services\n",
            "current price : $ 0 . 025\n",
            "we expect projected speculative price in next 5 days : $ 0 . 12\n",
            "we expect projected speculative price in next 15 days : $ 0 . 15\n",
            "vocalscape networks inc . is building a company that ' s revolutionizing the\n",
            "telecommunications industry with the most affordable phone systems , hardware ,\n",
            "online software , and rates in canada and the us . vocalscape , a company with\n",
            "global reach , is receiving international attention for the development of voice\n",
            "over ip ( voip ) application solutions , including the award - winning eyefontm , a\n",
            "softphone for real - time pc - to - phone . we are an advanced implementer of pbx\n",
            "systems for companies , call centers , itsps and service providers .\n",
            "vocalscape has created software and interactive solutions revolving around\n",
            "global communications and data voice convergence . companies use vocalscape for\n",
            "voice over internet protocol applications like ip pbxs , softswitches , pc 2 phone\n",
            "and web 2 phone , providing real - time human interaction and information delivery\n",
            "over the internet . through vocalscape ' s solutions , businesses can offer a\n",
            "quality voice service to anywhere in the world at rates that are significantly\n",
            "lower than current long distance charges . we develop software to run voip\n",
            "networks , and sell , install and service our own branded voip gateways and\n",
            "gatekeeper control software . we also license our software to customers who want\n",
            "to brand their own voip solutions .\n",
            "vocalscape is committed to making great technology ; challenging the status quo ,\n",
            "and building a 21 st century company that changes the way businesses communicate\n",
            "and interact through the internet .\n",
            "current price : $ 0 . 025\n",
            "we expect projected speculative price in next 5 days : $ 0 . 12\n",
            "we expect projected speculative price in next 15 days : $ 0 . 15\n",
            "breaking news - vocalscape inc . announces agreement to resell mix network\n",
            "services\n",
            "- - - - - - - - - -\n",
            "katonah , n . y . , / prnewswire - firstcall via comtex / - - vocalscape , inc . pink : vcsc ) ,\n",
            "an emerging leader in the development of voice over internet protocol ( voip )\n",
            "telephony solutions , announced today it has entered into a sales agent agreement\n",
            "with mix networks , inc . a voip enhanced telephony service provider .\n",
            "this agreement provides vocalscape ' s turnkey calling card customers with access\n",
            "to mix networks services including north american dids ( phone numbers ) and\n",
            "domestic long distance termination . vocalscape will also be able to supply their\n",
            "clients with enhanced voip products including pre - paid calling through mix\n",
            "networks north american network .\n",
            "we are excited to help companies launch voip business models using our solution\n",
            "with the whole picture from the software to the network needed to route the\n",
            "calls . mix networks gives us the ability to offer wholesale monthly flat rate\n",
            "plans and dids to our clients that allow for us to build business models like\n",
            "popular voip companies such as vonage and packet 8 , says ryan gibson , vp\n",
            "vocalscape networks\n",
            "some legal words before you continue :\n",
            "information within this email contains forward looking statements within the\n",
            "meaning of section 27 a of the securities act of 1933 and section 21 b of the\n",
            "securities exchange act of 1934 . any statements that express or involve\n",
            "discussions with respect to predictions , goals , expectations , beliefs , plans ,\n",
            "projections , objectives , assumptions or future events or performance are not\n",
            "statements of historical fact and may be forward looking statements . forward\n",
            "looking statements are based on expectations , estimates and projections at the\n",
            "time the statements are made that involve a number of risks and uncertainties\n",
            "which could cause actual results or events to differ materially from those\n",
            "presently anticipated . forward looking statements in this action may be\n",
            "identified through the use of words such as : projects , foresee , expects ,\n",
            "estimates , believes , understands will , part of : anticipates , or that\n",
            "by statements indicating certain actions may , could , or might occur . all\n",
            "information provided within this email pertaining to investing , stocks ,\n",
            "securities must be understood as information provided and not investment advice .\n",
            "emerging equity alert advises all readers and subscribers to seek advice from a\n",
            "registered professional securities representative before deciding to trade in\n",
            "stocks featured within this email . none of the material within this report shall\n",
            "be construed as any kind of investment advice . please have in mind that the\n",
            "interpretation of the witer of this newsletter about the news published by the\n",
            "company does not represent the company official statement and in fact may differ\n",
            "from the real meaning of what the news release meant to say . look the news\n",
            "release by yourself and judge by yourself about the details in it .\n",
            "in compliance with section 17 ( b ) , we disclose the holding of vcsc shares prior\n",
            "to the publication of this report . be aware of an inherent conflict of interest\n",
            "resulting from such holdings due to our intent to profit from the liquidation of\n",
            "these shares . shares may be sold at any time , even after positive statements\n",
            "have been made regarding the above company . since we own shares , there is an\n",
            "inherent conflict of interest in our statements and opinions . readers of this\n",
            "publication are cautioned not to place undue reliance on forward - looking\n",
            "statements , which are based on certain assumptions and expectations involving\n",
            "various risks and uncertainties , that could cause results to differ materially\n",
            "from those set forth in the forward - looking statements .\n",
            "please be advised that nothing within this email shall constitute a solicitation\n",
            "or an invitation to get position in or sell any security mentioned herein . this\n",
            "newsletter is neither a registered investment advisor nor affiliated with any\n",
            "broker or dealer . this newsletter was paid $ 49000 from third party to send this\n",
            "report . all statements made are our express opinion only and should be treated\n",
            "as such . we may own , take position and sell any securities mentioned at any\n",
            "time . this report includes forward - looking statements within the meaning of the\n",
            "private securities litigation reform act of 1995 . these statements may include\n",
            "terms as projected speculative price expect , believe , may , will ,\n",
            "soar move , undervalued and intend or similar terms .\n",
            " \n",
            "\n",
            " spam \n",
            "\n",
            "\n",
            "Subject: help !\n",
            "brian ,\n",
            "who do i talk to about getting daren farmer a labor distribution report . he\n",
            "needs to see what employees are hitting his rc . i know that we have\n",
            "discussed this prior and soem managers are receiving a monthly report but he\n",
            "is not . who can help us ? ? ?\n",
            "thank you !\n",
            "yvette\n",
            "x 3 . 5953 \n",
            "\n",
            " ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il dataset consiste in 4 colonne, la prima (senza nome) che rappresenta una sorta di indicizzazione delle righe, poi abbiamo la label che ci dice se il contenuto della mail è spam oppure no, il testo della mail, con anche il soggetto, e infine la colonna label ma in formato binario anziché stringa"
      ],
      "metadata": {
        "id": "0RAAiIuEu0C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Suddivisioni classi nel dataset di partenza\")\n",
        "print(\"Percentuale di eMail classificate come Spam: \", round(len(df[df.label == \"spam\"])/len(df),2), \"%\")\n",
        "print(\"Percentuale di eMail classificate come Non Spam: \", round(len(df[df.label == \"ham\"])/len(df),2), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4BCn3votRiH",
        "outputId": "56b08c97-7c01-4e97-8901-077fc2d60557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suddivisioni classi nel dataset di partenza\n",
            "Percentuale di eMail classificate come Spam:  0.29 %\n",
            "Percentuale di eMail classificate come Non Spam:  0.71 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il dataset non è perfettamente bilanciato, però comunque il divario tra le 2 classi non risulta cosi accentuato (la classe minoritaria è ben rappresentata lo stesso).\n",
        "\n",
        "Posso procedere senza dover andare ad applicare undersampling/oversampling."
      ],
      "metadata": {
        "id": "2BXRQM13uUSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA CLEANING"
      ],
      "metadata": {
        "id": "6xhyoOfUu5mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scarico le stopwords se non sono presenti\n",
        "try:\n",
        "    _ = stopwords.words(\"english\")\n",
        "except LookupError:\n",
        "    nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "english_stopwords = set(stopwords.words(\"english\"))  #uso il set per togliere eventuali duplicati\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "punctuation_table = str.maketrans({c: \" \" for c in string.punctuation})\n",
        "\n",
        "# uso la funzione per pulire il testo\n",
        "def data_cleaner(sentence: str) -> str:\n",
        "    sentence = sentence.lower()\n",
        "    sentence = sentence.translate(punctuation_table) #uso maketrans+translate al posto del for all'interno della funzione\n",
        "    doc = nlp(sentence)\n",
        "    lemmas = [tok.lemma_ for tok in doc if tok.is_alpha]\n",
        "    tokens = [tok for tok in lemmas if tok not in english_stopwords and len(tok) > 1]  # applico anche un filtro sulla lunghezza delle parole in quanti facendo alcuni\n",
        "                                                                                       # test mi sono trovato poi all'interno del dizionario lettere singole senza un senso preciso\n",
        "    tokens = [re.sub(r\"\\d\", \"\", tok) for tok in tokens if tok]\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "saIb3-R_hXbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#uso il TfidfVectorizer per dare i pesi a ciascun elemento delle varie parole contenute nelle mail\n",
        "vectorizer = TfidfVectorizer(\n",
        "    preprocessor=data_cleaner,\n",
        "    tokenizer=str.split, #applico la tokenizzazione splittando le varie parole\n",
        "    token_pattern=None, #qui metto token pattern = None visto che ho già effettuato il cleaning usando la funzione data_cleaner\n",
        "    min_df=3, #scarto i termini rari che appaiono in meno di 3 documenti, riduco il rumore e abbasso la dimensionalità\n",
        "    max_df=0.3 #scarto i termini che appaiono in più del 30% dei documenti (anche qui riduco la dimensionalità e tolgo i termini che appaiono molto spesso e quindi non sono informativi: tipo la parola \"subject\")\n",
        ")\n",
        "\n",
        "X = vectorizer.fit_transform(df[\"text\"].values)\n",
        "y = df[\"label\"].map({\"ham\": 0, \"spam\": 1}).values"
      ],
      "metadata": {
        "id": "Qk9d3Pq0hXZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gzBgmbYqkEw",
        "outputId": "d164beed-8c62-4a75-cbde-b4a126ac70f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx_W5dP-hXWs",
        "outputId": "f3809b57-dd50-44e6-d8ed-a9e3fa66ebda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 3996)\t0.09412193784134303\n",
            "  (0, 6716)\t0.23213511240934784\n",
            "  (0, 6714)\t0.1175491885550849\n",
            "  (0, 4517)\t0.12857747211720508\n",
            "  (0, 7182)\t0.15568808871249135\n",
            "  (0, 4823)\t0.144003705012492\n",
            "  (0, 6880)\t0.17311970842293198\n",
            "  (0, 7981)\t0.24281360198142626\n",
            "  (0, 4495)\t0.13844934838134543\n",
            "  (0, 3043)\t0.1944947698362905\n",
            "  (0, 8149)\t0.15421551417847493\n",
            "  (0, 3023)\t0.10867883077443628\n",
            "  (0, 7454)\t0.3058874198092447\n",
            "  (0, 7895)\t0.19644493414680173\n",
            "  (0, 2995)\t0.306053958851577\n",
            "  (0, 10532)\t0.11943907503643691\n",
            "  (0, 8004)\t0.232927438962433\n",
            "  (0, 10918)\t0.19232943932081387\n",
            "  (0, 8425)\t0.19779776513257435\n",
            "  (0, 125)\t0.181742043979165\n",
            "  (0, 7244)\t0.22910862257805456\n",
            "  (0, 4715)\t0.1046080905482578\n",
            "  (0, 2656)\t0.18292719213414182\n",
            "  (0, 1994)\t0.12490394604035944\n",
            "  (0, 7058)\t0.1026082465050001\n",
            "  :\t:\n",
            "  (5170, 8059)\t0.05440494103431993\n",
            "  (5170, 3083)\t0.06886906593097539\n",
            "  (5170, 1000)\t0.2151701572477338\n",
            "  (5170, 8138)\t0.0789394054667922\n",
            "  (5170, 1002)\t0.45037639075983366\n",
            "  (5170, 1135)\t0.07801989854723249\n",
            "  (5170, 7170)\t0.07743963287774555\n",
            "  (5170, 8381)\t0.24375798436707255\n",
            "  (5170, 10382)\t0.06613308448380018\n",
            "  (5170, 5334)\t0.05846781157530272\n",
            "  (5170, 6671)\t0.0677080085919125\n",
            "  (5170, 5676)\t0.10368940525389272\n",
            "  (5170, 5626)\t0.0908124406656816\n",
            "  (5170, 4294)\t0.0857988128722841\n",
            "  (5170, 2407)\t0.08807645921850639\n",
            "  (5170, 4421)\t0.06689781866576823\n",
            "  (5170, 10594)\t0.0843099694904798\n",
            "  (5170, 9708)\t0.0963406270842614\n",
            "  (5170, 8827)\t0.08807645921850639\n",
            "  (5170, 2419)\t0.1715976257445682\n",
            "  (5170, 5438)\t0.09752695632176432\n",
            "  (5170, 8516)\t0.1018688135028412\n",
            "  (5170, 4596)\t0.09882643297465084\n",
            "  (5170, 5643)\t0.09524930997554201\n",
            "  (5170, 2163)\t0.3339579318182974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dopo aver creato il dizionario e trasformato tutto il corpus documentale in formato numerico posso procedere con la creazione del modello di classificazione.\n",
        "In questo caso utilizzerò una regressione logistica"
      ],
      "metadata": {
        "id": "IQtIoFctkgyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"yellow\">***Classificatore eMail spam***</font>"
      ],
      "metadata": {
        "id": "qGeKcEgal6Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applico il solito train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "CeOpHC5Ll6Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creo il modello di regressione\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"HAM\", \"SPAM\"]))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiLt8LD5l6Mq",
        "outputId": "4a998c9d-6c34-43d0-99f0-6f865221bf90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         HAM       0.99      0.98      0.99       735\n",
            "        SPAM       0.95      0.99      0.97       300\n",
            "\n",
            "    accuracy                           0.98      1035\n",
            "   macro avg       0.97      0.98      0.98      1035\n",
            "weighted avg       0.98      0.98      0.98      1035\n",
            "\n",
            "Confusion Matrix:\n",
            " [[721  14]\n",
            " [  4 296]]\n",
            "Accuracy: 0.9826086956521739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con questo semplice modello di regressione logistica siamo stati in grado di ottenere un classificatore molto buono, in particolare abbiamo una accuracy complessiva di più del 98% (OTTIMO!!)"
      ],
      "metadata": {
        "id": "_icPmprXoH3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"yellow\">***Individuazione topics eMail spam***</font>"
      ],
      "metadata": {
        "id": "XeqVTxAmnIZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TOPICS = 10    #decido aribtrariamente di individuare 10 argomenti prinicipali\n",
        "\n",
        "#copio il dataframe (filtrando solo le righe spam), pulisco e applico la tokenizzazione\n",
        "spam_df = df[df.label == \"spam\"].copy()\n",
        "spam_clean = spam_df.text.apply(data_cleaner)\n",
        "spam_tokens = [doc.split() for doc in spam_clean]\n",
        "\n",
        "\n",
        "dictionary = corpora.Dictionary(spam_tokens)\n",
        "\n",
        "# vedo la percentuale con cui si presentano i token più ricorrenti, per capire poi quale soglia utilizzare per l'eliminazione dei token più frequenti\n",
        "if True:\n",
        "    import pandas as pd\n",
        "    num_docs = len(spam_tokens)\n",
        "    df_series  = pd.Series({dictionary[id]: cnt for id, cnt in dictionary.dfs.items()})\n",
        "    pct_series = (df_series / num_docs).sort_values(ascending=False)\n",
        "\n",
        "    print(\"\\nTop 25 tokens per frequenza nei documenti (prima del filtering):\")\n",
        "    for token, pct in pct_series.head(25).items():\n",
        "        print(f\"{token:15s}  {df_series[token]:4d} docs  ({pct*100:5.1f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD1uUmowxaYK",
        "outputId": "0e317e21-f723-4f06-9880-b3d0bd0acdfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 25 tokens per frequenza nei documenti (prima del filtering):\n",
            "subject          1499 docs  (100.0%)\n",
            "get               478 docs  ( 31.9%)\n",
            "http              475 docs  ( 31.7%)\n",
            "com               444 docs  ( 29.6%)\n",
            "please            313 docs  ( 20.9%)\n",
            "time              297 docs  ( 19.8%)\n",
            "email             296 docs  ( 19.7%)\n",
            "price             295 docs  ( 19.7%)\n",
            "good              281 docs  ( 18.7%)\n",
            "one               280 docs  ( 18.7%)\n",
            "www               263 docs  ( 17.5%)\n",
            "need              253 docs  ( 16.9%)\n",
            "new               253 docs  ( 16.9%)\n",
            "offer             251 docs  ( 16.7%)\n",
            "use               234 docs  ( 15.6%)\n",
            "go                231 docs  ( 15.4%)\n",
            "want              225 docs  ( 15.0%)\n",
            "take              221 docs  ( 14.7%)\n",
            "information       220 docs  ( 14.7%)\n",
            "click             216 docs  ( 14.4%)\n",
            "free              211 docs  ( 14.1%)\n",
            "like              208 docs  ( 13.9%)\n",
            "product           208 docs  ( 13.9%)\n",
            "make              203 docs  ( 13.5%)\n",
            "send              203 docs  ( 13.5%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#anche qui faccio un filtro su termini contenuti all'interno del dizionario, togliendo quelli troppo rari o eccessivamente presenti\n",
        "NO_BELOW = 3\n",
        "NO_ABOVE = 0.25 #applico 0.25 per togliere alcuni termini poco utili com http, com, get\n",
        "\n",
        "print(f\"Appicando filter_extremes(no_below={NO_BELOW}, no_above={NO_ABOVE})…\")\n",
        "\n",
        "dictionary.filter_extremes(no_below=NO_BELOW, no_above=NO_ABOVE)\n",
        "\n",
        "corpus = [dictionary.doc2bow(tokens) for tokens in spam_tokens]\n",
        "\n",
        "lda = models.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=NUM_TOPICS,\n",
        "    passes=10,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\n=== LDA Topics (SPAM) ===\")\n",
        "for i, topic in lda.print_topics(num_words=10):\n",
        "    print(f\"Topic {i}: {topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7ZFWNmKl6J5",
        "outputId": "3b9ed947-f556-4f19-8d37-490a1e8afe9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Appicando filter_extremes(no_below=3, no_above=0.25)…\n",
            "\n",
            "=== LDA Topics (SPAM) ===\n",
            "Topic 0: 0.009*\"say\" + 0.006*\"one\" + 0.005*\"gas\" + 0.004*\"source\" + 0.004*\"company\" + 0.004*\"story\" + 0.004*\"price\" + 0.004*\"project\" + 0.004*\"use\" + 0.004*\"full\"\n",
            "Topic 1: 0.008*\"online\" + 0.006*\"man\" + 0.005*\"well\" + 0.005*\"good\" + 0.005*\"med\" + 0.005*\"order\" + 0.005*\"time\" + 0.005*\"need\" + 0.004*\"account\" + 0.004*\"make\"\n",
            "Topic 2: 0.014*\"cialis\" + 0.012*\"viagra\" + 0.012*\"soft\" + 0.010*\"drug\" + 0.009*\"tab\" + 0.009*\"prescription\" + 0.007*\"hour\" + 0.007*\"new\" + 0.006*\"product\" + 0.006*\"pill\"\n",
            "Topic 3: 0.048*\"font\" + 0.047*\"td\" + 0.041*\"nbsp\" + 0.035*\"height\" + 0.030*\"width\" + 0.024*\"size\" + 0.022*\"align\" + 0.021*\"tr\" + 0.019*\"border\" + 0.018*\"color\"\n",
            "Topic 4: 0.011*\"computron\" + 0.010*\"please\" + 0.010*\"contact\" + 0.010*\"www\" + 0.008*\"free\" + 0.008*\"remove\" + 0.008*\"message\" + 0.008*\"mail\" + 0.007*\"email\" + 0.007*\"send\"\n",
            "Topic 5: 0.035*\"pill\" + 0.012*\"cd\" + 0.011*\"mg\" + 0.011*\"price\" + 0.009*\"paliourg\" + 0.009*\"microsoft\" + 0.008*\"save\" + 0.007*\"info\" + 0.007*\"viagra\" + 0.007*\"software\"\n",
            "Topic 6: 0.023*\"company\" + 0.014*\"statement\" + 0.012*\"stock\" + 0.009*\"information\" + 0.008*\"may\" + 0.008*\"security\" + 0.008*\"investment\" + 0.008*\"report\" + 0.007*\"within\" + 0.006*\"inc\"\n",
            "Topic 7: 0.007*\"rolex\" + 0.005*\"watch\" + 0.004*\"replica\" + 0.004*\"www\" + 0.004*\"price\" + 0.003*\"word\" + 0.003*\"want\" + 0.002*\"online\" + 0.002*\"visit\" + 0.002*\"xm\"\n",
            "Topic 8: 0.016*\"adobe\" + 0.014*\"window\" + 0.014*\"price\" + 0.011*\"xp\" + 0.011*\"professional\" + 0.010*\"office\" + 0.009*\"software\" + 0.008*\"microsoft\" + 0.008*\"ms\" + 0.008*\"photoshop\"\n",
            "Topic 9: 0.008*\"want\" + 0.008*\"rate\" + 0.007*\"know\" + 0.007*\"take\" + 0.007*\"new\" + 0.006*\"good\" + 0.006*\"email\" + 0.006*\"www\" + 0.006*\"low\" + 0.005*\"find\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10 argomenti forse sono un po' tanti. Provo a ridurre il numero da 10 a 5"
      ],
      "metadata": {
        "id": "JjJqwTCfy3jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TOPICS = 5\n",
        "lda = models.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=NUM_TOPICS,\n",
        "    passes=10,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"\\n=== LDA Topics (SPAM) ===\")\n",
        "for i, topic in lda.print_topics(num_words=10):\n",
        "    print(f\"Topic {i}: {topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lOvs7CdzHAe",
        "outputId": "0aa08743-e486-403c-98ca-38df3a3e10f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== LDA Topics (SPAM) ===\n",
            "Topic 0: 0.020*\"company\" + 0.012*\"statement\" + 0.010*\"stock\" + 0.008*\"information\" + 0.007*\"may\" + 0.007*\"investment\" + 0.007*\"security\" + 0.007*\"report\" + 0.006*\"within\" + 0.006*\"price\"\n",
            "Topic 1: 0.009*\"price\" + 0.005*\"good\" + 0.005*\"online\" + 0.005*\"save\" + 0.005*\"software\" + 0.005*\"adobe\" + 0.005*\"need\" + 0.004*\"microsoft\" + 0.004*\"want\" + 0.004*\"well\"\n",
            "Topic 2: 0.015*\"pill\" + 0.008*\"viagra\" + 0.007*\"cialis\" + 0.005*\"prescription\" + 0.005*\"soft\" + 0.005*\"drug\" + 0.004*\"mg\" + 0.004*\"tab\" + 0.003*\"good\" + 0.003*\"hour\"\n",
            "Topic 3: 0.032*\"font\" + 0.031*\"td\" + 0.026*\"nbsp\" + 0.023*\"height\" + 0.019*\"width\" + 0.016*\"size\" + 0.014*\"align\" + 0.014*\"tr\" + 0.012*\"color\" + 0.012*\"border\"\n",
            "Topic 4: 0.010*\"please\" + 0.009*\"www\" + 0.008*\"contact\" + 0.008*\"computron\" + 0.007*\"free\" + 0.007*\"email\" + 0.007*\"remove\" + 0.006*\"message\" + 0.006*\"send\" + 0.006*\"mail\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok direi che qui abbiamo chiaramente individuato qualche tipologia ricorrente di argomenti presenti nella email Spam:\n",
        "- Topic 0: sembra essere riferito all'ambito investimenti (magari pubblicità di qualche broker finanziario)\n",
        "- Topic 1: qui invece vendita (probabilmente truffaldina) di software per il PC\n",
        "- Topic 2: questo invece riguarda la vendita di prodotti legati al mondo del sesso\n",
        "- Topic 3: non sembrano avere un significato preciso, probabilmente mail con argomenti vari sono stati accorpate assieme\n",
        "- Topic 4: anche qui l'argomento non è chiaro, ma probabilmente sono mail che invitano a cliccare/visitare qualche sito (probabilmente malevolo)"
      ],
      "metadata": {
        "id": "A2ijBxJh79Rp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"yellow\">***Distanza semantica tra gli argomenti delle mail SPAM***</font>"
      ],
      "metadata": {
        "id": "oWBdaes893mZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qui di seguito mi creo una matrice per andare a vedere coppia a coppia la distanza semantica tra un argomento e l'altro. Distanza sempre calcolata utilizzando la cosine similiraty"
      ],
      "metadata": {
        "id": "AeVtxELD-QSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topic_vecs = np.zeros((NUM_TOPICS, len(dictionary)))\n",
        "for t in range(NUM_TOPICS):\n",
        "    for wid, weight in lda.get_topic_terms(t, topn=len(dictionary)):\n",
        "        topic_vecs[t, wid] = weight\n",
        "\n",
        "dist_matrix = np.zeros((NUM_TOPICS, NUM_TOPICS))\n",
        "for i in range(NUM_TOPICS):\n",
        "    for j in range(i + 1, NUM_TOPICS):\n",
        "        d = cosine(topic_vecs[i], topic_vecs[j])\n",
        "        dist_matrix[i, j] = dist_matrix[j, i] = d\n",
        "\n",
        "print(dist_matrix)\n",
        "\n",
        "mean_dist = dist_matrix[np.triu_indices(NUM_TOPICS, k=1)].mean() #prendo solo la parte di matrice triangolare superiore per il calcolo della media (escludendo anche la diagonale che tanto è sempre 0)\n",
        "print(f\"\\nDistanza media fra i vari argomenti: {mean_dist:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCh0_UgohXUE",
        "outputId": "84e318a8-b0dc-429a-ea36-f7cb69a8d83e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.64314482 0.81040995 0.92186581 0.66537708]\n",
            " [0.64314482 0.         0.57014181 0.84959885 0.51464942]\n",
            " [0.81040995 0.57014181 0.         0.90413364 0.72849621]\n",
            " [0.92186581 0.84959885 0.90413364 0.         0.82895915]\n",
            " [0.66537708 0.51464942 0.72849621 0.82895915 0.        ]]\n",
            "\n",
            "Distanza media fra i vari argomenti: 0.7437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possiamo notare come gli argomenti più simili siano il Topic 1, con il topic 4. (anche se non trovo un significato a questo)\n",
        "\n",
        "Inoltre topic 1 e 2 sono abbastanza simili, in quanto riguardano entrambi una vendita online.\n",
        "\n",
        "In generale la distanza media fra i vari argomenti è 0.74, quindi abbastanza alta, le mail SPAM posso essere quindi di tipologia abbastanza varia."
      ],
      "metadata": {
        "id": "SVwWWYX6_KTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"yellow\">***Identificazione organizzazioni***</font>"
      ],
      "metadata": {
        "id": "bRdAo56MAHwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nel codice seguente scarico prima di tutto il dizionario delle entità da spacy (e da questo filtro solo le entità segnate con \"ORG\"), e successivamente vado a vedere nelle mail lecite quali sono le organizzazioni più citate."
      ],
      "metadata": {
        "id": "KdpK4FzbAWgY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NLP_NER = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def extract_orgs(text: str):\n",
        "    return [ent.text for ent in NLP_NER(text).ents if ent.label_ == \"ORG\"]\n",
        "\n",
        "ham_df = df[df.label == \"ham\"].copy()\n",
        "ham_df[\"orgs\"] = ham_df.text.apply(extract_orgs)\n",
        "\n",
        "all_orgs = [org for sublist in ham_df.orgs for org in sublist]\n",
        "org_freq = pd.Series(all_orgs).value_counts()\n",
        "print(\"\\n=== Top 20 Organisations in HAM ===\")\n",
        "print(org_freq.head(20))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7VxHrR7hXRa",
        "outputId": "182b9481-5edc-4da4-d7cb-09627bed8e12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Top 20 Organisations in HAM ===\n",
            "\u0001                                       271\n",
            "doc                                     178\n",
            "north america corp .                    166\n",
            "ami chokshi / corp / enron              153\n",
            "xls                                     123\n",
            "enron north america corp .               81\n",
            "pg & e                                   71\n",
            "riley / hou /                            57\n",
            "mary m smith / hou /                     53\n",
            "exxon                                    52\n",
            "enron corp .                             51\n",
            "boas / hou                               45\n",
            "coastal oil & gas corporation\\n          43\n",
            "lamadrid / hou                           42\n",
            "capital & trade resources corp .         39\n",
            "texaco                                   38\n",
            "ami chokshi / corp / enron @ enron\\n     38\n",
            "stella l morris / hou                    38\n",
            "d & h gas company                        37\n",
            "zivley / hou                             36\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Andando a cercare in internet sembrano essere tutte compagnie legate al mondo Energetico (Vendita di gas naturale, petrolio, energia elettrica in generale e il suo smistamento).\n",
        "\n",
        "L'area geografica di provenienza è il nord america (Stati Uniti in particolare)\n",
        "\n",
        "Quindi le mail lecite probabilmente provengono da qualche azienda (forse di consulenza) che fa consulenza per compagnie energetiche o magari qualche società che collabora con esse (tipo per la costruzione delle infrastrutture)."
      ],
      "metadata": {
        "id": "DEsfj-nXCjug"
      }
    }
  ]
}